## KNN 工作原理

近朱者赤近墨者黑

### 计算步骤

1. 计算待分类物与他物之间的距离
2. 统计距离最近的K个邻居  
3. 对于K个最近的邻居 哪个最多 待分类物属于谁

### 如何选择 `K` 值
0. k值太小，容易过拟合；k值太大，容易欠拟合
1. 工程上 使用交叉验证的思路进行验证（即要根据实际数据实践得出最佳k值）
  - 大部分样本作为训练集
  - 剩余部分用于预测
  - 一般的 我们把 `K` 值选取在较小的范围
  - 验证集上准确率最高的一个作为最终 `K` 值

### 距离如何计算

> 距离代表相似度，和差异性成正比

距离计算的方式（点(x1,x2,...xn)和点(y1,y2,...yn)）

1. 欧氏距离（欧几里得距离）
![](WechatIMG78.jpeg)
2. 曼哈顿距离
![](WechatIMG79.jpeg)

3. 闵可夫斯基距离（p代表空间的维度）
![](WechatIMG80.jpeg)

4. 切比雪夫距离

```
max(|x1-y1|,|x2-y2|)
```
5. 余弦距离

  - 计算两个向量的夹角，是在方向上计算两者之间的差异，对绝对值不敏感
  - 常用于搜索关键词推荐，兴趣相关度

> 前三种常用

### `KD` 树

概念

`KD` 树是对数据点在K维空间中划分的一种数据结构
 - 每个节点都是k维数值点的二叉树，非常方便存储k维空间的数据


## `KNN` 回归
1. KNN不仅可以做分类，还可以做回归
2. 找到这个点的 `K` 个最近邻居（用某点已知属性算） 然后将这些邻居的属性（用某点已知属性算）的平均值赋值给该点 可以得到该点的属性（某点未知属性）
