## 分类回归树(Classification And Regression Tree,简称CART)

- ID3和C4.5可以生成二叉树或多叉树
- CART算法只支持二叉树
  1. 可以作为分类树
  2. 可以作为回归树

- 分类树可以处理离散数据，输出的是样本的类别
- 回归树可以对连续型数据进行预测，也就是数据在某个区间内都有取值的可能，它输出的是一个连续值，即回归预测结果。

### 测试数据

![测试数据](测试数据.jpeg)

## CART分类树
### 采用基尼系数作为标准

1. 反映样本的不确定性
2. 基尼系数越小 样本之间的差异性小 不确定程度低
3. CART算法构造分类树的时候 选择基尼系数最小的属性作为属性的划分

### 实例

假设t为节点 该节点的GINI系数的计算公式为
![实例](GINI.jpeg)

## CART回归树
预测结果是连续值  
### 采用样本的混乱程度，即离散程度作为标准
1. 最小绝对偏差(LAD)
2. 最小二乘偏差(LSD)

## CART决策树的剪枝

CCP方法，一种后剪枝方法  
节点的表面误差率增益=节点t子树被剪枝后的误差变化/减掉的叶子数量