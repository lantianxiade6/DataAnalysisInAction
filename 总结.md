# 爬虫
请求后返回json：
```python
import requests
import json
html=requests.get(url).text#发起Requests请求，得到文本结果
response=json.loads(html,encoding='utf-8')#JSON解析
for image in response['images']:#按键取值
    pass
```

请求后返回图片：
```python
import requests
pic=requests.get(src,timeout=10)#发起请求，得到图片结果，设置超时10秒
fp=open('./test.jpg','wb')#新建一张空图片
fp.write(pic.content)#写入图片内容
fp.close()#关闭图片
```

# 数据清洗
[数据质量](./11/README.md)   
[数据变化](./13/README.md)   
[数据清洗](./19/README.md) ；[数据清洗](./23/README.md) 

# 数据可视化
[数据可视化](./15/README.md) 

# 分类算法
## ID3
- 采用信息熵作为标准  
[详情](./19/README.md) 
```python
'''ID3分类树'''
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_val_score

clf = DecisionTreeClassifier(criterion='entropy')#ID3决策树分类器，分类标准是信息熵
clf.fit(train_features, train_labels)#放入训练集的特征和分类标识进行训练
pred_labels = clf.predict(test_features)# 决策树预测
# 得到决策树准确率（有测试集的test_labels才用它，否则用K 折交叉验证）
acc_decision_tree = round(clf.score(test_features, test_labels), 6)
print(u'score 准确率为 %.4lf' % acc_decision_tree)
# 使用 K 折交叉验证 统计决策树准确率
print(u'cross_val_score 准确率为 %.4lf' % np.mean(cross_val_score(clf, train_features, train_labels, cv=10)))
```
## C4.5
- 采用信息增益率作为标准
## CART
- 采用基尼系数作为标准  
[详情](./18/README.md) 
```python
'''CART分类树'''
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.datasets import load_iris

train_test_split(features, labels, test_size=0.33, random_state=0)# 随机抽取 33% 的数据作为测试集，其余为训练集
clf = DecisionTreeClassifier(criterion='gini')#初始化决策树分类器，以基尼系数为分类指标
clf = clf.fit(train_features, train_labels)#放入训练集，包括特征集和分类标识，进行训练
test_predict = clf.predict(test_features)#放入测试集的特征集，进行预测
score = accuracy_score(test_labels, test_predict)#计算准确率
print("CART 分类树准确率 %.4lf" % score)
```
```python
'''CART回归树'''
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_boston
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from sklearn.tree import DecisionTreeRegressor

train_features, test_features, train_price, test_price = train_test_split(features, prices, test_size=0.33, random_state=0)# 随机抽取 33% 的数据作为测试集，其余为训练集

dtr = DecisionTreeRegressor()#初始化 CART 回归树
dtr = dtr.fit(train_features, train_price)#放入训练集，包括特征集和房价，进行训练
predict_price = dtr.predict(test_features)#放入测试集的特征集，进行预测
# 预测结果与测试集结果作比对
print('回归树二乘偏差均值',mean_squared_error(test_price,predict_price))
print('回归树绝对值偏差均值',mean_absolute_error(test_price,predict_price))
```
```python
'''决策树/回归树可视化'''
from sklearn import tree
import graphviz#先在终端跑pip install graphviz
dot_data=tree.export_graphviz(clf,out_file=None)#输出DOT格式的决策树
graph=graphviz.Source(dot_data)
graph.render("分类树","./18/")#会在目录下生成一个pdf
```
## 朴素贝叶斯
朴素贝叶斯分类常用于文本分类，尤其对于英文等语言来说，分类效果很好。它常用于垃圾文本过滤、情感预测、推荐系统等。 
注：多项式朴素贝叶斯传入的数据不能有负数
[详情](./21/README.md) 
```python
from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn import metrics
stop_words=[line.strip() for line in open('./stopword.txt','r',encoding='utf-8-sig').readlines()]
tf = TfidfVectorizer(stop_words=stop_words, max_df=0.5)#stop_words为'english'或list,并过滤掉超过max_df的词语
train_features = tf.fit_transform(train_news.data)#转为文档词条矩阵，作为特征集，注意用的是fit_transform,即训练+转换
clf = MultinomialNB(alpha=0.001).fit(train_features, train_news.target)#多项式贝叶斯分类器
test_features=tf.transform(test_news.data)#要用和训练集一样的词语作为特征集，注意用的是_transform,即仅转换
predicted_labels=clf.predict(test_features)#预测测试集
print('accuracy_score:',metrics.accuracy_score(test_news.target, predicted_labels))#计算准确率
```
## SVM（支持向量机）
SVM是一个寻找超平面的过程
[详情](./23/README.md) 
```python
'''svm'''
from sklearn import svm
from sklearn import metrics
model = svm.SVC()# 创建SVM分类器
model.fit(train_X,train_y)# 用训练集做训练
prediction=model.predict(test_X)# 用测试集做预测
print('准确率: ', metrics.accuracy_score(prediction,test_y))#准确率
```
```python
'''linear svm'''
from sklearn import svm
from sklearn import metrics
model = svm.LinearSVC()#linearsvm
model.fit(train_X,train_y)# 用训练集做训练
prediction=model.predict(test_X)# 用测试集做预测
print('准确率: ', metrics.accuracy_score(prediction,test_y))#准确率
```
## KNN
对于待分类物而言，它的K个最近的邻居中哪个类最多，那它就属于谁
[详情](./25/README.md) 
```python
from sklearn.metrics import accuracy_score
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier()# 创建KNN分类器
knn.fit(train_ss_x, train_y) #训练
predict_y = knn.predict(test_ss_x) #预测
print("KNN准确率: %.4lf" % accuracy_score(test_y,predict_y))#KNN准确率: 0.9756
```
## Adaboost


# 聚类算法
## K-Means
## EM（最大期望值算法）

# 关联分析
## Apriori

# 连接分析
## PageRank

till chapter 25